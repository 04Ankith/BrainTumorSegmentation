{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dc5141d-0925-4867-b222-c5eb2ea68b21",
   "metadata": {},
   "source": [
    "### Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98dd4dd2-c5a9-4d8f-a9f4-fbe7969504ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sathw\\.conda\\envs\\brain\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de432a7-9ba0-40b0-9736-d9bbb511c90b",
   "metadata": {},
   "source": [
    "### Data Loader and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56cb6075-ee65-4907-93f4-b276d6615a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(img):\n",
    "    img = np.nan_to_num(img)\n",
    "    return (img - np.min(img)) / (np.max(img) - np.min(img) + 1e-8)\n",
    "\n",
    "def load_data(root_dir, image_size=(128, 128)):\n",
    "    images, masks = [], []\n",
    "\n",
    "    for folder in sorted(os.listdir(root_dir)):\n",
    "        folder_path = os.path.join(root_dir, folder)\n",
    "        t1c_path = glob(os.path.join(folder_path, '*-t1c.nii'))[0]\n",
    "        seg_path = glob(os.path.join(folder_path, '*-seg.nii'))[0]\n",
    "\n",
    "        t1c_img = nib.load(t1c_path).get_fdata()\n",
    "        seg_img = nib.load(seg_path).get_fdata()\n",
    "\n",
    "        for i in range(t1c_img.shape[2]):\n",
    "            img_slice = normalize(t1c_img[:, :, i])\n",
    "            mask_slice = seg_img[:, :, i]\n",
    "\n",
    "            img_slice = cv2.resize(img_slice, image_size)\n",
    "            mask_slice = cv2.resize(mask_slice, image_size, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "            # Relabel: replace 4 â†’ 3 to make labels sequential (0,1,2,3)\n",
    "            mask_slice = np.where(mask_slice == 4, 3, mask_slice)\n",
    "            mask_slice = tf.keras.utils.to_categorical(mask_slice, num_classes=4)\n",
    "\n",
    "            images.append(img_slice[..., np.newaxis])\n",
    "            masks.append(mask_slice)\n",
    "\n",
    "    return np.array(images), np.array(masks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "358c7dce-bddf-4978-aadc-b9dc00cfee59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "images, masks = load_data(\"../data/brats-men-train/\")\n",
    "x_train, x_val, y_train, y_val = train_test_split(images, masks, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552bdb5d-6f8e-4432-89ea-ec28b3b36304",
   "metadata": {},
   "source": [
    "### Hybrid UNet with Attention and Transformers\n",
    "#### Attention Block + Transformer Bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37c3884a-49d8-4a23-a65e-1b7be0150261",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_block(x, g):\n",
    "    inter_channels = x.shape[-1]\n",
    "    theta_x = layers.Conv2D(inter_channels, 1)(x)\n",
    "    phi_g = layers.Conv2D(inter_channels, 1)(g)\n",
    "    f = layers.Activation('relu')(layers.add([theta_x, phi_g]))\n",
    "    psi = layers.Conv2D(1, 1, activation='sigmoid')(f)\n",
    "    return layers.multiply([x, psi])\n",
    "\n",
    "def transformer_block(x, num_heads=4, ff_dim=64):\n",
    "    x1 = layers.LayerNormalization()(x)\n",
    "    attn_output = layers.MultiHeadAttention(num_heads=num_heads, key_dim=ff_dim)(x1, x1)\n",
    "    x2 = layers.Add()([x, attn_output])\n",
    "    x3 = layers.LayerNormalization()(x2)\n",
    "    ffn = tf.keras.Sequential([\n",
    "        layers.Dense(ff_dim, activation='relu'),\n",
    "        layers.Dense(x.shape[-1])\n",
    "    ])\n",
    "    return layers.Add()([x2, ffn(x3)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b045d990-9b5d-4c24-83c1-fed2190acc81",
   "metadata": {},
   "source": [
    "#### Hybrid UNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60e08211-7d5e-4527-b695-f9e1a4adfaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_hybrid_unet(input_shape=(128, 128, 1)):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Encoder\n",
    "    c1 = layers.Conv2D(32, 3, activation='relu', padding='same')(inputs)\n",
    "    c1 = layers.Conv2D(32, 3, activation='relu', padding='same')(c1)\n",
    "    p1 = layers.MaxPooling2D()(c1)\n",
    "\n",
    "    c2 = layers.Conv2D(64, 3, activation='relu', padding='same')(p1)\n",
    "    c2 = layers.Conv2D(64, 3, activation='relu', padding='same')(c2)\n",
    "    p2 = layers.MaxPooling2D()(c2)\n",
    "\n",
    "    # Bottleneck + Transformer\n",
    "    b = layers.Conv2D(128, 3, activation='relu', padding='same')(p2)\n",
    "    b_flat = layers.Reshape((-1, 128))(b)\n",
    "    b_trans = transformer_block(b_flat)\n",
    "    b = layers.Reshape((b.shape[1], b.shape[2], 128))(b_trans)\n",
    "\n",
    "    # Decoder with Attention\n",
    "    up1 = layers.UpSampling2D()(b)\n",
    "    att1 = attention_block(c2, up1)\n",
    "    m1 = layers.Concatenate()([up1, att1])\n",
    "    c3 = layers.Conv2D(64, 3, activation='relu', padding='same')(m1)\n",
    "    c3 = layers.Conv2D(64, 3, activation='relu', padding='same')(c3)\n",
    "\n",
    "    up2 = layers.UpSampling2D()(c3)\n",
    "    att2 = attention_block(c1, up2)\n",
    "    m2 = layers.Concatenate()([up2, att2])\n",
    "    c4 = layers.Conv2D(32, 3, activation='relu', padding='same')(m2)\n",
    "    c4 = layers.Conv2D(32, 3, activation='relu', padding='same')(c4)\n",
    "\n",
    "    # Output: 4-class softmax\n",
    "    outputs = layers.Conv2D(4, 1, activation='softmax')(c4)\n",
    "    return models.Model(inputs, outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc7d7c1-0e0d-4d2e-8ec4-548131d4dbfe",
   "metadata": {},
   "source": [
    "### Compile and Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5029dbb5-679d-486c-8b4a-2ab7e4c1f358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sathw\\.conda\\envs\\brain\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sathw\\.conda\\envs\\brain\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sathw\\.conda\\envs\\brain\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\sathw\\.conda\\envs\\brain\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sathw\\.conda\\envs\\brain\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.0303 - accuracy: 0.9943\n",
      "Epoch 1: saving model to ../models/checkpoints\\unet_epoch_01.h5\n",
      "524/524 [==============================] - 774s 1s/step - loss: 0.0303 - accuracy: 0.9943 - val_loss: 0.0256 - val_accuracy: 0.9945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sathw\\.conda\\envs\\brain\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.0243 - accuracy: 0.9953\n",
      "Epoch 2: saving model to ../models/checkpoints\\unet_epoch_02.h5\n",
      "524/524 [==============================] - 703s 1s/step - loss: 0.0243 - accuracy: 0.9953 - val_loss: 0.0235 - val_accuracy: 0.9945\n",
      "Epoch 3/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.0214 - accuracy: 0.9952\n",
      "Epoch 3: saving model to ../models/checkpoints\\unet_epoch_03.h5\n",
      "524/524 [==============================] - 1040s 2s/step - loss: 0.0214 - accuracy: 0.9952 - val_loss: 0.0272 - val_accuracy: 0.9946\n",
      "Epoch 4/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.0162 - accuracy: 0.9961\n",
      "Epoch 4: saving model to ../models/checkpoints\\unet_epoch_04.h5\n",
      "524/524 [==============================] - 1448s 3s/step - loss: 0.0162 - accuracy: 0.9961 - val_loss: 0.0138 - val_accuracy: 0.9963\n",
      "Epoch 5/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.0131 - accuracy: 0.9966\n",
      "Epoch 5: saving model to ../models/checkpoints\\unet_epoch_05.h5\n",
      "524/524 [==============================] - 633s 1s/step - loss: 0.0131 - accuracy: 0.9966 - val_loss: 0.0144 - val_accuracy: 0.9964\n",
      "Epoch 6/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.0115 - accuracy: 0.9969\n",
      "Epoch 6: saving model to ../models/checkpoints\\unet_epoch_06.h5\n",
      "524/524 [==============================] - 551s 1s/step - loss: 0.0115 - accuracy: 0.9969 - val_loss: 0.0110 - val_accuracy: 0.9962\n",
      "Epoch 7/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.0085 - accuracy: 0.9975\n",
      "Epoch 7: saving model to ../models/checkpoints\\unet_epoch_07.h5\n",
      "524/524 [==============================] - 564s 1s/step - loss: 0.0085 - accuracy: 0.9975 - val_loss: 0.0084 - val_accuracy: 0.9974\n",
      "Epoch 8/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.0078 - accuracy: 0.9977\n",
      "Epoch 8: saving model to ../models/checkpoints\\unet_epoch_08.h5\n",
      "524/524 [==============================] - 558s 1s/step - loss: 0.0078 - accuracy: 0.9977 - val_loss: 0.0077 - val_accuracy: 0.9975\n",
      "Epoch 9/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 0.9981\n",
      "Epoch 9: saving model to ../models/checkpoints\\unet_epoch_09.h5\n",
      "524/524 [==============================] - 537s 1s/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.0060 - val_accuracy: 0.9980\n",
      "Epoch 10/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 0.9982\n",
      "Epoch 10: saving model to ../models/checkpoints\\unet_epoch_10.h5\n",
      "524/524 [==============================] - 527s 1s/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.0132 - val_accuracy: 0.9956\n",
      "Epoch 11/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.0059 - accuracy: 0.9982\n",
      "Epoch 11: saving model to ../models/checkpoints\\unet_epoch_11.h5\n",
      "524/524 [==============================] - 524s 1s/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.0056 - val_accuracy: 0.9982\n",
      "Epoch 12/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 0.9986\n",
      "Epoch 12: saving model to ../models/checkpoints\\unet_epoch_12.h5\n",
      "524/524 [==============================] - 533s 1s/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 0.0048 - val_accuracy: 0.9983\n",
      "Epoch 13/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 0.9985\n",
      "Epoch 13: saving model to ../models/checkpoints\\unet_epoch_13.h5\n",
      "524/524 [==============================] - 529s 1s/step - loss: 0.0043 - accuracy: 0.9985 - val_loss: 0.0041 - val_accuracy: 0.9986\n",
      "Epoch 14/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9987\n",
      "Epoch 14: saving model to ../models/checkpoints\\unet_epoch_14.h5\n",
      "524/524 [==============================] - 527s 1s/step - loss: 0.0037 - accuracy: 0.9987 - val_loss: 0.0044 - val_accuracy: 0.9984\n",
      "Epoch 15/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 0.9987\n",
      "Epoch 15: saving model to ../models/checkpoints\\unet_epoch_15.h5\n",
      "524/524 [==============================] - 522s 997ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.0039 - val_accuracy: 0.9986\n",
      "Epoch 16/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9989\n",
      "Epoch 16: saving model to ../models/checkpoints\\unet_epoch_16.h5\n",
      "524/524 [==============================] - 516s 984ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.0041 - val_accuracy: 0.9986\n",
      "Epoch 17/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9989\n",
      "Epoch 17: saving model to ../models/checkpoints\\unet_epoch_17.h5\n",
      "524/524 [==============================] - 522s 997ms/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.0050 - val_accuracy: 0.9983\n",
      "Epoch 18/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 0.9987\n",
      "Epoch 18: saving model to ../models/checkpoints\\unet_epoch_18.h5\n",
      "524/524 [==============================] - 505s 965ms/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 0.0032 - val_accuracy: 0.9988\n",
      "Epoch 19/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9990\n",
      "Epoch 19: saving model to ../models/checkpoints\\unet_epoch_19.h5\n",
      "524/524 [==============================] - 502s 957ms/step - loss: 0.0026 - accuracy: 0.9990 - val_loss: 0.0030 - val_accuracy: 0.9989\n",
      "Epoch 20/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 0.9986\n",
      "Epoch 20: saving model to ../models/checkpoints\\unet_epoch_20.h5\n",
      "524/524 [==============================] - 493s 941ms/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 0.0076 - val_accuracy: 0.9980\n",
      "Epoch 21/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 0.9990\n",
      "Epoch 21: saving model to ../models/checkpoints\\unet_epoch_21.h5\n",
      "524/524 [==============================] - 501s 956ms/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.0031 - val_accuracy: 0.9989\n",
      "Epoch 22/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9991\n",
      "Epoch 22: saving model to ../models/checkpoints\\unet_epoch_22.h5\n",
      "524/524 [==============================] - 498s 950ms/step - loss: 0.0023 - accuracy: 0.9991 - val_loss: 0.0040 - val_accuracy: 0.9986\n",
      "Epoch 23/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9992\n",
      "Epoch 23: saving model to ../models/checkpoints\\unet_epoch_23.h5\n",
      "524/524 [==============================] - 503s 960ms/step - loss: 0.0022 - accuracy: 0.9992 - val_loss: 0.0032 - val_accuracy: 0.9988\n",
      "Epoch 24/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9992\n",
      "Epoch 24: saving model to ../models/checkpoints\\unet_epoch_24.h5\n",
      "524/524 [==============================] - 1890s 4s/step - loss: 0.0021 - accuracy: 0.9992 - val_loss: 0.0028 - val_accuracy: 0.9990\n",
      "Epoch 25/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 0.9988\n",
      "Epoch 25: saving model to ../models/checkpoints\\unet_epoch_25.h5\n",
      "524/524 [==============================] - 923s 2s/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.0057 - val_accuracy: 0.9982\n",
      "Epoch 26/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.9990\n",
      "Epoch 26: saving model to ../models/checkpoints\\unet_epoch_26.h5\n",
      "524/524 [==============================] - 835s 2s/step - loss: 0.0027 - accuracy: 0.9990 - val_loss: 0.0029 - val_accuracy: 0.9989\n",
      "Epoch 27/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.9993\n",
      "Epoch 27: saving model to ../models/checkpoints\\unet_epoch_27.h5\n",
      "524/524 [==============================] - 538s 1s/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 0.0026 - val_accuracy: 0.9991\n",
      "Epoch 28/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9993\n",
      "Epoch 28: saving model to ../models/checkpoints\\unet_epoch_28.h5\n",
      "524/524 [==============================] - 529s 1s/step - loss: 0.0018 - accuracy: 0.9993 - val_loss: 0.0030 - val_accuracy: 0.9989\n",
      "Epoch 29/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9993\n",
      "Epoch 29: saving model to ../models/checkpoints\\unet_epoch_29.h5\n",
      "524/524 [==============================] - 477s 910ms/step - loss: 0.0018 - accuracy: 0.9993 - val_loss: 0.0025 - val_accuracy: 0.9991\n",
      "Epoch 30/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.9992\n",
      "Epoch 30: saving model to ../models/checkpoints\\unet_epoch_30.h5\n",
      "524/524 [==============================] - 472s 901ms/step - loss: 0.0020 - accuracy: 0.9992 - val_loss: 0.0138 - val_accuracy: 0.9973\n",
      "Epoch 31/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9988\n",
      "Epoch 31: saving model to ../models/checkpoints\\unet_epoch_31.h5\n",
      "524/524 [==============================] - 474s 905ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.0026 - val_accuracy: 0.9990\n",
      "Epoch 32/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9993\n",
      "Epoch 32: saving model to ../models/checkpoints\\unet_epoch_32.h5\n",
      "524/524 [==============================] - 476s 909ms/step - loss: 0.0017 - accuracy: 0.9993 - val_loss: 0.0024 - val_accuracy: 0.9991\n",
      "Epoch 33/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9993\n",
      "Epoch 33: saving model to ../models/checkpoints\\unet_epoch_33.h5\n",
      "524/524 [==============================] - 473s 903ms/step - loss: 0.0018 - accuracy: 0.9993 - val_loss: 0.0022 - val_accuracy: 0.9992\n",
      "Epoch 34/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 0.9994\n",
      "Epoch 34: saving model to ../models/checkpoints\\unet_epoch_34.h5\n",
      "524/524 [==============================] - 471s 899ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.0022 - val_accuracy: 0.9992\n",
      "Epoch 35/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9993\n",
      "Epoch 35: saving model to ../models/checkpoints\\unet_epoch_35.h5\n",
      "524/524 [==============================] - 477s 911ms/step - loss: 0.0017 - accuracy: 0.9993 - val_loss: 0.0026 - val_accuracy: 0.9990\n",
      "Epoch 36/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 0.9994\n",
      "Epoch 36: saving model to ../models/checkpoints\\unet_epoch_36.h5\n",
      "524/524 [==============================] - 471s 900ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.0022 - val_accuracy: 0.9992\n",
      "Epoch 37/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 0.9994\n",
      "Epoch 37: saving model to ../models/checkpoints\\unet_epoch_37.h5\n",
      "524/524 [==============================] - 473s 902ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.0022 - val_accuracy: 0.9992\n",
      "Epoch 38/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9988\n",
      "Epoch 38: saving model to ../models/checkpoints\\unet_epoch_38.h5\n",
      "524/524 [==============================] - 473s 903ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.0025 - val_accuracy: 0.9991\n",
      "Epoch 39/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 0.9994\n",
      "Epoch 39: saving model to ../models/checkpoints\\unet_epoch_39.h5\n",
      "524/524 [==============================] - 471s 898ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.0021 - val_accuracy: 0.9992\n",
      "Epoch 40/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9995\n",
      "Epoch 40: saving model to ../models/checkpoints\\unet_epoch_40.h5\n",
      "524/524 [==============================] - 481s 917ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.0022 - val_accuracy: 0.9992\n",
      "Epoch 41/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9995\n",
      "Epoch 41: saving model to ../models/checkpoints\\unet_epoch_41.h5\n",
      "524/524 [==============================] - 473s 902ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.0020 - val_accuracy: 0.9992\n",
      "Epoch 42/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9995\n",
      "Epoch 42: saving model to ../models/checkpoints\\unet_epoch_42.h5\n",
      "524/524 [==============================] - 473s 902ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.0025 - val_accuracy: 0.9991\n",
      "Epoch 43/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 0.9991\n",
      "Epoch 43: saving model to ../models/checkpoints\\unet_epoch_43.h5\n",
      "524/524 [==============================] - 518s 989ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0023 - val_accuracy: 0.9992\n",
      "Epoch 44/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 0.9995\n",
      "Epoch 44: saving model to ../models/checkpoints\\unet_epoch_44.h5\n",
      "524/524 [==============================] - 639s 1s/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0020 - val_accuracy: 0.9993\n",
      "Epoch 45/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 0.9995\n",
      "Epoch 45: saving model to ../models/checkpoints\\unet_epoch_45.h5\n",
      "524/524 [==============================] - 471s 898ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.0020 - val_accuracy: 0.9993\n",
      "Epoch 46/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 0.9995\n",
      "Epoch 46: saving model to ../models/checkpoints\\unet_epoch_46.h5\n",
      "524/524 [==============================] - 471s 899ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.0021 - val_accuracy: 0.9992\n",
      "Epoch 47/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 0.9995\n",
      "Epoch 47: saving model to ../models/checkpoints\\unet_epoch_47.h5\n",
      "524/524 [==============================] - 473s 904ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.0019 - val_accuracy: 0.9993\n",
      "Epoch 48/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 0.9994\n",
      "Epoch 48: saving model to ../models/checkpoints\\unet_epoch_48.h5\n",
      "524/524 [==============================] - 471s 900ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.0021 - val_accuracy: 0.9992\n",
      "Epoch 49/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 0.9995\n",
      "Epoch 49: saving model to ../models/checkpoints\\unet_epoch_49.h5\n",
      "524/524 [==============================] - 613s 1s/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.0019 - val_accuracy: 0.9993\n",
      "Epoch 50/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 0.9995\n",
      "Epoch 50: saving model to ../models/checkpoints\\unet_epoch_50.h5\n",
      "524/524 [==============================] - 474s 904ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.0019 - val_accuracy: 0.9993\n",
      "Epoch 51/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9995\n",
      "Epoch 51: saving model to ../models/checkpoints\\unet_epoch_51.h5\n",
      "524/524 [==============================] - 472s 900ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.0033 - val_accuracy: 0.9988\n",
      "Epoch 52/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9995\n",
      "Epoch 52: saving model to ../models/checkpoints\\unet_epoch_52.h5\n",
      "524/524 [==============================] - 473s 903ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.0022 - val_accuracy: 0.9992\n",
      "Epoch 53/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 0.9996\n",
      "Epoch 53: saving model to ../models/checkpoints\\unet_epoch_53.h5\n",
      "524/524 [==============================] - 470s 898ms/step - loss: 0.0010 - accuracy: 0.9996 - val_loss: 0.0019 - val_accuracy: 0.9993\n",
      "Epoch 54/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.9996\n",
      "Epoch 54: saving model to ../models/checkpoints\\unet_epoch_54.h5\n",
      "524/524 [==============================] - 547s 1s/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.0023 - val_accuracy: 0.9992\n",
      "Epoch 55/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9994\n",
      "Epoch 55: saving model to ../models/checkpoints\\unet_epoch_55.h5\n",
      "524/524 [==============================] - 477s 911ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.0032 - val_accuracy: 0.9989\n",
      "Epoch 56/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9990\n",
      "Epoch 56: saving model to ../models/checkpoints\\unet_epoch_56.h5\n",
      "524/524 [==============================] - 473s 902ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.0021 - val_accuracy: 0.9992\n",
      "Epoch 57/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 0.9995\n",
      "Epoch 57: saving model to ../models/checkpoints\\unet_epoch_57.h5\n",
      "524/524 [==============================] - 473s 903ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.0021 - val_accuracy: 0.9992\n",
      "Epoch 58/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 0.9996\n",
      "Epoch 58: saving model to ../models/checkpoints\\unet_epoch_58.h5\n",
      "524/524 [==============================] - 475s 906ms/step - loss: 0.0010 - accuracy: 0.9996 - val_loss: 0.0019 - val_accuracy: 0.9993\n",
      "Epoch 59/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 9.6389e-04 - accuracy: 0.9996\n",
      "Epoch 59: saving model to ../models/checkpoints\\unet_epoch_59.h5\n",
      "524/524 [==============================] - 491s 937ms/step - loss: 9.6389e-04 - accuracy: 0.9996 - val_loss: 0.0018 - val_accuracy: 0.9993\n",
      "Epoch 60/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 9.4103e-04 - accuracy: 0.9996\n",
      "Epoch 60: saving model to ../models/checkpoints\\unet_epoch_60.h5\n",
      "524/524 [==============================] - 495s 945ms/step - loss: 9.4103e-04 - accuracy: 0.9996 - val_loss: 0.0018 - val_accuracy: 0.9994\n",
      "Epoch 61/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 9.9124e-04 - accuracy: 0.9996\n",
      "Epoch 61: saving model to ../models/checkpoints\\unet_epoch_61.h5\n",
      "524/524 [==============================] - 487s 930ms/step - loss: 9.9124e-04 - accuracy: 0.9996 - val_loss: 0.0019 - val_accuracy: 0.9993\n",
      "Epoch 62/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 0.9996\n",
      "Epoch 62: saving model to ../models/checkpoints\\unet_epoch_62.h5\n",
      "524/524 [==============================] - 483s 923ms/step - loss: 0.0010 - accuracy: 0.9996 - val_loss: 0.0019 - val_accuracy: 0.9993\n",
      "Epoch 63/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 9.3645e-04 - accuracy: 0.9996\n",
      "Epoch 63: saving model to ../models/checkpoints\\unet_epoch_63.h5\n",
      "524/524 [==============================] - 489s 933ms/step - loss: 9.3645e-04 - accuracy: 0.9996 - val_loss: 0.0022 - val_accuracy: 0.9993\n",
      "Epoch 64/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9992\n",
      "Epoch 64: saving model to ../models/checkpoints\\unet_epoch_64.h5\n",
      "524/524 [==============================] - 485s 926ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.0021 - val_accuracy: 0.9993\n",
      "Epoch 65/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 9.8698e-04 - accuracy: 0.9996\n",
      "Epoch 65: saving model to ../models/checkpoints\\unet_epoch_65.h5\n",
      "524/524 [==============================] - 487s 928ms/step - loss: 9.8698e-04 - accuracy: 0.9996 - val_loss: 0.0019 - val_accuracy: 0.9993\n",
      "Epoch 66/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 8.7636e-04 - accuracy: 0.9996\n",
      "Epoch 66: saving model to ../models/checkpoints\\unet_epoch_66.h5\n",
      "524/524 [==============================] - 495s 945ms/step - loss: 8.7636e-04 - accuracy: 0.9996 - val_loss: 0.0018 - val_accuracy: 0.9994\n",
      "Epoch 67/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 8.2654e-04 - accuracy: 0.9997\n",
      "Epoch 67: saving model to ../models/checkpoints\\unet_epoch_67.h5\n",
      "524/524 [==============================] - 483s 922ms/step - loss: 8.2654e-04 - accuracy: 0.9997 - val_loss: 0.0018 - val_accuracy: 0.9993\n",
      "Epoch 68/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 8.4114e-04 - accuracy: 0.9997\n",
      "Epoch 68: saving model to ../models/checkpoints\\unet_epoch_68.h5\n",
      "524/524 [==============================] - 488s 931ms/step - loss: 8.4114e-04 - accuracy: 0.9997 - val_loss: 0.0019 - val_accuracy: 0.9993\n",
      "Epoch 69/100\n",
      "524/524 [==============================] - ETA: 0s - loss: 8.6959e-04 - accuracy: 0.9996\n",
      "Epoch 69: saving model to ../models/checkpoints\\unet_epoch_69.h5\n",
      "524/524 [==============================] - 498s 950ms/step - loss: 8.6959e-04 - accuracy: 0.9996 - val_loss: 0.0020 - val_accuracy: 0.9993\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "# Make sure the directory exists\n",
    "os.makedirs('../models/checkpoints', exist_ok=True)\n",
    "# Build and compile the model\n",
    "model = build_hybrid_unet()\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# Callbacks\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath='../models/checkpoints/unet_epoch_{epoch:02d}.h5',\n",
    "        save_freq='epoch',\n",
    "        save_weights_only=False,  # Set to True if you only want weights\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=16,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2254ce0-02a4-49b9-a155-a7e088633496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved Successfully\n"
     ]
    }
   ],
   "source": [
    "model.save(\"../models/finalunet.h5\")\n",
    "print(\"Model Saved Successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3f216ea-b75d-4b26-a82f-33ecc14be1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 30s 1s/step - loss: 0.0018 - accuracy: 0.9993\n",
      "loss: 0.0018\n",
      "accuracy: 0.9993\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_val, y_val, verbose=1)\n",
    "metric_names = model.metrics_names\n",
    "for name, value in zip(metric_names, results):\n",
    "    print(f\"{name}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df470866-97ca-4493-9968-8daf0c660a9a",
   "metadata": {},
   "source": [
    "#### Evaluate and print metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcb22e3-3c14-4fdf-b648-6207556beaa0",
   "metadata": {},
   "source": [
    "### Dice Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12be0848-c316-4fc2-8c16-dc78d2597f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, smooth=1e-6):\n",
    "    y_true_f = tf.reshape(y_true, [-1, tf.shape(y_true)[-1]])\n",
    "    y_pred_f = tf.reshape(y_pred, [-1, tf.shape(y_pred)[-1]])\n",
    "    intersection = tf.reduce_sum(y_true_f * y_pred_f, axis=0)\n",
    "    union = tf.reduce_sum(y_true_f + y_pred_f, axis=0)\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    return tf.reduce_mean(dice)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1ec44d-0d39-4f50-bdce-f612412c4930",
   "metadata": {},
   "source": [
    "### Mean IoU (Jaccard Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78776cf7-43a1-41e4-bdd5-7424f9092a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_iou(y_true, y_pred, smooth=1e-6):\n",
    "    y_true = tf.argmax(y_true, axis=-1)\n",
    "    y_pred = tf.argmax(y_pred, axis=-1)\n",
    "    y_true_f = tf.reshape(y_true, [-1])\n",
    "    y_pred_f = tf.reshape(y_pred, [-1])\n",
    "\n",
    "    iou = tf.keras.metrics.MeanIoU(num_classes=4)\n",
    "    iou.update_state(y_true_f, y_pred_f)\n",
    "    return iou.result()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d29fde1-5776-4dc6-934a-80b705d7bfc8",
   "metadata": {},
   "source": [
    "### Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb27b057-3811-470b-b336-3ecc41186434",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_metric(y_true, y_pred, smooth=1e-6):\n",
    "    y_true_f = tf.reshape(y_true, [-1, tf.shape(y_true)[-1]])\n",
    "    y_pred_f = tf.reshape(y_pred, [-1, tf.shape(y_pred)[-1]])\n",
    "    tp = tf.reduce_sum(y_true_f * y_pred_f, axis=0)\n",
    "    fp = tf.reduce_sum(y_pred_f * (1 - y_true_f), axis=0)\n",
    "    precision = (tp + smooth) / (tp + fp + smooth)\n",
    "    return tf.reduce_mean(precision)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215d83f8-79ad-406f-b78c-6b5b33c3ee88",
   "metadata": {},
   "source": [
    "### Sensitivity (Recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39b37404-3b4c-414e-b297-c4c984396d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitivity_metric(y_true, y_pred, smooth=1e-6):\n",
    "    y_true_f = tf.reshape(y_true, [-1, tf.shape(y_true)[-1]])\n",
    "    y_pred_f = tf.reshape(y_pred, [-1, tf.shape(y_pred)[-1]])\n",
    "    tp = tf.reduce_sum(y_true_f * y_pred_f, axis=0)\n",
    "    fn = tf.reduce_sum(y_true_f * (1 - y_pred_f), axis=0)\n",
    "    sensitivity = (tp + smooth) / (tp + fn + smooth)\n",
    "    return tf.reduce_mean(sensitivity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd63847-94f0-464b-8019-ab83558926a2",
   "metadata": {},
   "source": [
    "### Specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cfcc19be-4da8-4801-aa56-d300f2e9b37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def specificity_metric(y_true, y_pred, smooth=1e-6):\n",
    "    y_true_f = tf.reshape(y_true, [-1, tf.shape(y_true)[-1]])\n",
    "    y_pred_f = tf.reshape(y_pred, [-1, tf.shape(y_pred)[-1]])\n",
    "    tn = tf.reduce_sum((1 - y_true_f) * (1 - y_pred_f), axis=0)\n",
    "    fp = tf.reduce_sum((1 - y_true_f) * y_pred_f, axis=0)\n",
    "    specificity = (tn + smooth) / (tn + fp + smooth)\n",
    "    return tf.reduce_mean(specificity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557feb9f-cffd-4a46-9417-65d5434ccbd7",
   "metadata": {},
   "source": [
    "### Final Integration in Model Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "009b405c-1ab3-4f2b-9a42-fd282bda5b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        dice_coef,\n",
    "        mean_iou,\n",
    "        precision_metric,\n",
    "        sensitivity_metric,\n",
    "        specificity_metric\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "657bed10-be0f-4e40-badc-4eadc5e31c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankit\\anaconda3\\envs\\ankith\\lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ankit\\anaconda3\\envs\\ankith\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 39\u001b[0m\n\u001b[0;32m     36\u001b[0m     fp \u001b[38;5;241m=\u001b[39m K\u001b[38;5;241m.\u001b[39msum((\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m y_true) \u001b[38;5;241m*\u001b[39m y_pred)\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tn \u001b[38;5;241m/\u001b[39m (tn \u001b[38;5;241m+\u001b[39m fp \u001b[38;5;241m+\u001b[39m K\u001b[38;5;241m.\u001b[39mepsilon())\n\u001b[1;32m---> 39\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m     40\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     41\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     42\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     43\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     44\u001b[0m         dice_coef,\n\u001b[0;32m     45\u001b[0m         mean_iou,\n\u001b[0;32m     46\u001b[0m         precision_metric,\n\u001b[0;32m     47\u001b[0m         sensitivity_metric,\n\u001b[0;32m     48\u001b[0m         specificity_metric\n\u001b[0;32m     49\u001b[0m     ]\n\u001b[0;32m     50\u001b[0m )\n\u001b[0;32m     52\u001b[0m results \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(x_val, y_val, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     53\u001b[0m metric_names \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mmetrics_names\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "# Custom Dice Coefficient\n",
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(K.round(y_pred))\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "# Mean IoU\n",
    "def mean_iou(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "    intersect = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n",
    "    union = K.sum(y_true,[1,2,3])+K.sum(y_pred,[1,2,3])-intersect\n",
    "    return K.mean((intersect + 1.0) / (union + 1.0), axis=0)\n",
    "\n",
    "# Precision\n",
    "def precision_metric(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "    tp = K.sum(y_true * y_pred)\n",
    "    fp = K.sum((1 - y_true) * y_pred)\n",
    "    return tp / (tp + fp + K.epsilon())\n",
    "\n",
    "# Sensitivity (Recall)\n",
    "def sensitivity_metric(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "    tp = K.sum(y_true * y_pred)\n",
    "    fn = K.sum(y_true * (1 - y_pred))\n",
    "    return tp / (tp + fn + K.epsilon())\n",
    "\n",
    "# Specificity\n",
    "def specificity_metric(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "    tn = K.sum((1 - y_true) * (1 - y_pred))\n",
    "    fp = K.sum((1 - y_true) * y_pred)\n",
    "    return tn / (tn + fp + K.epsilon())\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        dice_coef,\n",
    "        mean_iou,\n",
    "        precision_metric,\n",
    "        sensitivity_metric,\n",
    "        specificity_metric\n",
    "    ]\n",
    ")\n",
    "\n",
    "results = model.evaluate(x_val, y_val, verbose=1)\n",
    "metric_names = model.metrics_names\n",
    "\n",
    "for name, value in zip(metric_names, results):\n",
    "    print(f\"{name}: {value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086443c8-02d5-4d40-86ec-b02ba4df5f04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
